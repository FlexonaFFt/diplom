# Техническое задание на разработку образовательной платформы «Контест + Курсы»

## 1. Назначение и цели проекта

Платформа предназначена для:

1. проведения публичных контестов/практикумов с автоматической проверкой решений и сбором данных для датасета;
2. управления учебными материалами и адаптивной рекомендацией контента на основе первичного тестирования знаний и последующей диагностики.

Цели:
- обеспечить прозрачный и воспроизводимый процесс решения задач студентами (домашние работы и экзамены);
- собрать качественный датасет решений и метаданных для дальнейшего обучения моделей в рамках улучшения качества обучения;
- реализовать адаптивную подачу учебных материалов на основе IRT/байесовского оценивания знаний.
## 2. Термины и сокращения

- Контест — набор задач с автоматической проверкой решений.
- Домашнее задание (ДЗ) — свободная отправка решений (вставка кода, загрузка файлов).
- Экзамен — режим с таймером, запретом вставки текста в редактор и запретом загрузки файлов.
- IRT (Item Response Theory) — теория тестовых заданий (3PL-модель: параметры a — различимость, d — сложность, c — угадывание).
- Рекомендательный вектор тем — вектор T ∈ ℝⁿ, где каждая компонента соответствует оценке освоения темы.
- Judge — изолированная служба выполнения и проверки решений.
- Админка — веб-интерфейс для преподавателей/администраторов.
- MVP — минимально жизнеспособная версия.
## 3. Соглашение

- Данная версия технического задания носит информационный характер, все совпадения случайны.
- Техническое задание в процессе доработки и редактирования.
## 4. Границы системы и роли пользователей

Роли:
- Гость: регистрация, ознакомление с описанием курсов/контестов.
- Студент: прохождение курсов и тестов, отправка решений, просмотр результатов.
- Преподаватель: создание курсов, лекций, квизов; формирование домашних заданий и экзаменов; просмотр аналитики.
- Администратор: управление пользователями и ролями, задачами, контрольными работами, настройками и параметрами системы; формирование выгрузок датасета.
  
Границы:
- Веб-клиент и REST API для всех функций.
- Серверная часть с базой данных, очередями задач и judge-исполнителем.
- Интеграции на этапе MVP: e-mail/пароль аутентификация.

## 5. Требования к функциональности
### 5.1. Подсистема «Контест»
#### 5.1.1. Типы заданий

- Домашнее задание:
    - Редактор кода с возможностью вставки текста.
    - Загрузка файлов решений (архив, отдельные файлы) — формат настраиваемый.
    - Множественные отправки без штрафов (политика ретраев еще не обсуждалась).
- Экзамен:
    - Встроенный таймер на каждую задачу и/или на весь вариант.
    - Блокировка вставки из буфера обмена в редакторе (frontend-ограничение) и серверный аудит событий вставки/ввода.
    - Запрет загрузки файлов; решения вводятся только вручную в редакторе.
    - Зафиксированное окно доступности, автосохранение черновика, автосдача по истечении времени.

#### 5.1.2. Отправка и проверка решений

- Поддерживаемый язык на этапе MVP: Python 3.12.3
    
- Формы отправки:
    - Текстовая вставка кода (ДЗ/Экзамен; в Экзамене без вставки).
    - Загрузка файлов (только ДЗ).
- Проверка:
    - Автоматическая проверка в judge-сервисе по тестам преподавателя.
    - Ресурсные лимиты: время, память, размер вывода — настраиваемые под задачи.
    - Типы тестов: публичные (видны студенту) и скрытые (только для проверки).
    - Результаты: вердикт (OK/WA/TLE/MLE/RE/CE), лог исполнения, покрытие тестов.
    - Базовая валидация до запуска judge: синтаксис, размер, запрещённые зависимости/импорты.
- Протокол отчётности по посылке:
    - Снимок исходников, метаданные, ресурсы, вердикты, хэш-суммы.

#### 5.1.3. Плагиат-аудит

- Сравнение на идентичность:
    - Нормализация исходников, вычисление хэшей (MD5/SHA-256) и простые текстовые меры (Jaccard по токенам).
- Аналитика временных паттернов:
    - Выявление групп аномально синхронных отправок между пользователями, корреляция с идентичными вердиктами/хэшами.
- Отчёт для преподавателя:
    - Списки совпадений, тепловые карты времени отправок, экспорт CSV/JSON.

#### 5.1.4. Админка (контест)

- CRUD задач и наборов задач (контрольные/экзамены/домашки).
- Настройки: лимиты ресурсов, политика повторных попыток, окно доступности, таймеры.
- Управление тестами: загрузка/редактирование, пометка публичных/скрытых.
- Просмотр статистики: распределение вердиктов, попыток, среднее время решения, плагиат-сигналы.
- Экспорт датасета решений и метаданных.

#### 5.1.5. Сбор данных для датасета

- Сохранять для каждой посылки:
    - user_id (псевдонимизированный при экспорте), problem_id, вариант/режим, исходный код/файлы, timestamp(UTC+3), длительность решения (IDE-время), вердикты, ресурсы, хэши, количество редактирований, события paste/keypress (агрегировано).
- Первичная схема экспорта: Parquet/CSV + JSON-мета.
- Механизм псевдонимизации и удаления персональных данных по запросу.
- Версионирование датасета (semver), фиксированный словарь полей и дата-каталога.
### 5.2. Подсистема «Курсы»
#### 5.2.1. Каталог курсов и лекций

- Структура: Курс → Разделы → Лекции.
- Для каждой лекции: текст/видео/слайды, материалы для чтения, связанный квиз.
- Пометка обязательных и рекомендованных материалов.

#### 5.2.2. Первичное тестирование и рекомендация

- Банк вопросов с параметрами IRT (a, d, c).
- Проведение стартового теста с контролем времени и случайной подачей вопросов.
- Оценка уровня знаний по темам:
    - 3PL-логистическая модель с апостериорным байесовским апдейтом по темам.
    - Результат — рекомендательный вектор T = (T1,…,Tn), 0…1.
- Рекомендации:
    - Формирование списка тем/лекций к изучению на основе T и порогов.
    - Перепрохождение стартового теста по запросу или после прогресса.

#### 5.2.3. Проверка знаний и адаптация сложности

- После каждой лекции — квиз по материалу.
- Домашнее задание — в подсистеме «Контест» без таймера.
- При устойчивых верных ответах по теме — повышение сложности последующих лекций/квизов.
- Отчёт студенту: прогресс по темам, слабые места, рекомендации.

#### 5.2.4. Помощник лекции (Q&A)

- Контекстный поиск по материалам текущей лекции.
- Вопрос-ответ внутри лекции на базе подключаемого LLM-API.
- Журнал вопросов с привязкой к лекции для улучшения материалов.
- Ограничение: ответы строятся только по контенту лекции и связанных источниках (RAG).

#### 5.2.5. Визуализация зависимостей (опционально)

- Просмотр графа тем/зависимостей: вершины — темы, рёбра — предпосылки.
- Подсветка зон риска для конкретного студента по вектору T.

### 5.3. Общие функции

- Регистрация/аутентификация (e-mail + пароль), восстановление доступа.
- Профиль пользователя: прогресс, история посылок, рекомендации.
- Уведомления: результаты проверок, дедлайны, рекомендации.
- Поиск по задачам, курсам, лекциям.

## 6. Требования к интерфейсам и API

- REST API (JSON), версионирование `/api/v1`.
- Основные ресурсы:
    - `/auth/*` — регистрация, вход, refresh токены.
        
    - `/users/*` — профиль, прогресс.
        
    - `/problems/*`, `/assignments/*`, `/exams/*` — задачи и наборы.
        
    - `/submissions/*` — отправки решений.
        
    - `/plagiarism/*` — отчёты плагиата (только для ролей staff).
        
    - `/datasets/*` — экспорт датасета (только админы).
        
    - `/courses/*`, `/lectures/*`, `/quizzes/*` — контент и квизы.
        
    - `/assessment/*` — первичное тестирование и рекомендации.
        
    - `/assistant/*` — Q&A по лекции.
        
- Документация API: OpenAPI/Swagger, доступна по `/docs`.

## 7. Архитектура и технологический стек

- Backend: FastAPI (async), Python 3.12.3
- БД: PostgreSQL 14+.
- Кэш/очередь: Redis 7+.
- Фоновые задачи: Celery (проверка решений, плагиат-аудит, экспорт датасета).
- Judge-исполнитель:
    - Изолированная среда (контейнер на базе Python) с ограничениями CPU/Memory/Timeout.
    - Интерфейс: получение задания + тестов → запуск → возврат протокола.
- Хранилище файлов: локально для dev, S3-совместимое для prod (MinIO).
- Тестирование: pytest, покрытие ≥ 70% для ядра проверки.
- CI: GitHub Actions (линтинг, тесты, миграции).
- Frontend (MVP): одностраничное приложение на React/Vite или стандартные шаблоны Jinja2; редактор кода — Monaco/CodeMirror.

Расширяемость языков:
- Абстракция «LanguageRunner» с конфигурацией компиляции/запуска.
- На этапе MVP — `PythonRunner`; на следующих этапах — `CppRunner`, `JavaRunner` и т.д.

## 8. Модель данных (основные сущности)

Примерно такие, будут точно известны после этапа проектирования БД:

- `users(id, email, password_hash, role, created_at, ...)`
    
- `courses(id, title, description, ...)`
    
- `sections(id, course_id, title, order, ...)`
    
- `lectures(id, section_id, title, content, resources, ...)`
    
- `quizzes(id, lecture_id, title, time_limit, ...)`
    
- `quiz_questions(id, quiz_id, text, options, answer_key, ...)`
    
- `topics(id, code, title, description)`
    
- `topic_links(src_topic_id, dst_topic_id)` — граф зависимостей.
    
- `irt_items(id, topic_id, stem, a, d, c)`
    
- `irt_sessions(id, user_id, started_at, finished_at, result_vector_json)`
    
- `irt_responses(session_id, item_id, is_correct, response_time_ms)`
    
- `problem_sets(id, type {homework, exam}, title, time_window_from, time_window_to, overall_timer_sec, settings_json)`
    
- `problems(id, title, statement_md, input_spec, output_spec, constraints, public_tests, hidden_tests, runner_config)`
    
- `attachments(id, owner_user_id, problem_id, path, checksum, ...)`
    
- `submissions(id, user_id, problem_id, problem_set_id, lang, source, files_manifest, verdict, cpu_ms, mem_kb, created_at, paste_events, keypress_stats, code_hash)`
    
- `plagiarism_cases(id, group_key, reason, score, details_json)`
    
- `dataset_releases(id, version, schema_json, storage_path, created_at)`
    
- `audit_log(id, actor_id, action, entity, entity_id, payload, ts)`
    

## 9. Нефункциональные требования

- Производительность: обработка одиночной отправки ≤ 5 секунд при типовом наборе тестов; очередь — не более 50 одновременно активных задач на одном воркере.
- Масштабируемость: горизонтальное масштабирование воркеров Celery и экземпляров API.
- Надёжность: автоповтор фоновых задач при сбое, идемпотентность операций экспорта.
- Безопасность:
    - JWT-аутентификация, роль-based доступ.
    - Ограничение загрузок по типам/размеру, антивирус-скан (опционально, обсудить).
    - Санитайзинг пользовательского контента, защита от XSS/CSRF.
    - Жёсткая изоляция judge (контейнер, seccomp-профиль, no-network).
- Конфиденциальность:
    - Псевдонимизация при экспорте датасета.
    - Удаление/анонимизация по запросу пользователя (обсудить).
- Логирование и мониторинг:
    - Структурированные логи JSON, трассировка запросов.
    - Метрики: RPS, latency, ошибки, очередь задач, доля вердиктов.
- Качество и тестирование:
    - Unit/Integration тесты, e2e-сценарии для критичных путей.
    - Проверка IRT-оценивания на синтетических наборах (точность ≥ 95% восстановления параметров в контролируемом эксперименте).
- UX:
    - Адаптивная верстка, сохранение черновиков, понятные сообщения об ошибках.
    - Доступность: контрастность, навигация с клавиатуры.

## 10. Ограничения и допущения

- На этапе MVP поддерживается только Python и один тип judge-контейнера.
- Боковая прокторинговая функциональность (веб-камера, захват экрана) не входит в MVP. Но это возможно сделать в будущем при доработке проекта (обсудить дальнейшее развитие идеи).
- Блокировка вставки в режиме Экзамен — на стороне клиента; сервер фиксирует события paste/keypress для аудита.

## 11. План работ и этапы

### Этап 0. Подготовка (1 неделя)

- Инициализация репозитория, базовая CI/CD.
- Проектирование схемы БД и контрактов API.

### Этап 1. Контест-MVP (3–4 недели)

- Роли, аутентификация.
- CRUD задач, наборов, публичные/скрытые тесты.
- Отправка решений (Python), judge в контейнере, вердикты.
- Домашний режим целиком.
- Сбор и сохранение метаданных, базовый экспорт.
- Плагиат: идентичность + временные корреляции.
- pytest-покрытие ядра ≥ 70%.
  
Критерии приёмки: успешная демонстрация ДЗ-контеста с несколькими задачами и массовыми отправками, отчёт плагиата и экспорт датасета.

### Этап 2. Экзамен (2 недели)

- Таймеры задач/варианта, автосдача.
- Блокировка paste и аудит событий.
- Окно доступности контрольной.

Критерии приёмки: экзамен с таймерами, невозможность вставки, корректная автосдача и учёт нарушений.

### Этап 3. Курсы и IRT (3–4 недели)

- Каталог курсов/лекций, квизы.
- Первичное тестирование, оценка T по IRT (3PL), рекомендации.
- Домашки после лекций через контест.

Критерии приёмки: формирование вектора T и рекомендаций; повышение сложности при прогрессе.

### Этап 4. Помощник лекции и отчётность (2 недели)

- Q&A на базе лекционного корпуса (RAG).
- Расширенный экспорт датасета (Parquet+JSON-мета), версия 1.0.0.

Критерии приёмки: корректные ответы помощника в пределах материалов лекции; формирование релиза датасета.

## 12. Критерии приёмки (суммарно)

- Все ключевые энд-поинты задокументированы в OpenAPI формате.
- Проверка решений в изоляции, вердикты и логи доступны пользователю.
- Экзамен с таймером и запретом вставки, аудит событий.
- Плагиат-отчёт формируется и выгружается.
- IRT-оценка выдаёт воспроизводимый рекомендательный вектор T.
- Квизы и домашки после лекций работают, прогресс фиксируется.
- Экспорт датасета соответствует описанной схеме и проходит валидацию.
- Набор автотестов проходит в CI.
## 13. Управление рисками

- Риск небезопасного исполнения кода: строгая изоляция контейнеров, no-network, ограничение привилегий.
- Риск ложных срабатываний плагиата: отчёты носят рекомендательный характер, финальное решение — за преподавателем.
- Риск перегрузки judge: очередь и масштабирование воркеров, ограничение частоты отправок.
- Риск недостоверных IRT-оценок при малом числе вопросов: минимальный объём стартового теста и контроль качества банка заданий.

## 14. Документация

- Руководство пользователя (студент/преподаватель).
- Руководство администратора.
- Техническая документация (архитектура, деплой, миграции).
- Описание схемы датасета и процедур анонимизации.
- Методика IRT-оценивания и валидационные эксперименты.

## 15. Лицензирование и правовые аспекты

- Политика конфиденциальности и пользовательское соглашение.
- Согласие на обработку данных и включение решений в датасет в обезличенном виде.
- Лицензии сторонних библиотек.

## 16. Приложения

### 16.1. Сценарии использования (выборочно)

- Студент проходит стартовый тест → получает вектор T → видит рекомендованные лекции → проходит квиз → выполняет ДЗ в контесте.
- Преподаватель создаёт экзамен → задаёт таймер и окно доступности → студенты проходят без вставки текста → преподаватель получает отчёты.
- Администратор выгружает релиз датасета v1.0.0 для исследований и создания новых моделей.

### 16.2. Формат экспорта датасета (MVP)

- `submissions.parquet`: `submission_id, user_pseudo, problem_id, set_type, lang, code_text, code_hash, verdict, cpu_ms, mem_kb, created_at_utc, keypress_stats_json, paste_events_count`.
- `problems.json`: метаданные задач, тесты (хэши/идентификаторы), ограничения.
- `irt_results.parquet`: `user_pseudo, session_id, topic_code, T_value, ts_utc`.

### 16.3. Конвенции разработки
- Версионирование проекта в github для удобства командной разработки.
- Логи: JSON, поля `ts, level, service, request_id, user_id, action, status`.

---

## Технические детали реализации (возможно редактирование в процессе)

### A. Endpoints (основные)

- `POST /api/v1/auth/register`, `POST /api/v1/auth/login`, `POST /api/v1/auth/refresh`
- `GET /api/v1/problems`, `POST /api/v1/problems` (staff), `PATCH /api/v1/problems/{id}` (staff)
- `POST /api/v1/submissions` — создание посылки; тело: `{problem_id, problem_set_id?, lang, source|files}`
- `GET /api/v1/submissions/{id}` — статус, вердикты, логи
- `GET /api/v1/plagiarism/reports` (staff)
- `POST /api/v1/problem-sets` (staff) — создание ДЗ/экзамена; настройки таймера, окна, лимитов
- `POST /api/v1/assessment/start`, `POST /api/v1/assessment/answer`, `GET /api/v1/assessment/result`
- `GET /api/v1/courses`, `GET /api/v1/lectures/{id}`, `GET /api/v1/quizzes/{id}`, `POST /api/v1/quizzes/{id}/submit`
- `POST /api/v1/assistant/query` — `{lecture_id, question}` → `{answer, sources}`

### B. Judge

- Контейнер Python с предустановленным набором библиотек (список в образе).
- Контракт входа: архив тестов + конфиг лимитов + исходники; выхода: протокол по каждому тесту и суммарный вердикт.
- Ограничения: `--cpus`, `--memory`, `ulimit` и отключённая сеть.

### C. IRT/Рекомендации

- 3PL: `P(correct | θ) = c + (1 - c) / (1 + exp(-a(θ - d)))`.
- Оценка θ по темам: MAP-оценка с нормальным приором, пошаговый апдейт по ответам.
- Рекомендация: темы с `T_i < τ_low` — обязательные; `τ_low ≤ T_i < τ_high` — рекомендованные; `T_i ≥ τ_high` — закрепление.

### D. Экзамен: таймер и анти-вставка

- Клиент: блокировка `paste`/`drop`, отслеживание `keypress`/скорости ввода, авто-сейв.
- Сервер: хранение событий (агрегированно), автосдача по истечении времени, «заморозка» редактора.
### E. Плагиат

- Хэши нормализованного кода + Jaccard по токенам.
- Временные кластеры отправок; отчёты с порогами и конфигом чувствительности.

---

## Приёмочные тесты (выборка)

1. Домашнее задание: три посылки, корректная проверка, видимость логов и публичных тестов.
2. Экзамен: недоступность вставки, таймер завершает работу, посылка фиксируется.
3. Judge: ограничение времени работает, решение с бесконечным циклом получает TLE.
4. Плагиат: две идентичные посылки — уведомление в отчёте, совпадающие хэши.
5. IRT: на синтетических ответах воспроизводится известный вектор T с погрешностью ≤ 0.05.
6. Помощник: ответы содержат ссылки на фрагменты лекции, без внешних источников.
7. Экспорт датасета: формируется релиз с верной схемой, поля соответствуют описанию.

---

## Готовность к расширению

- Добавление языков: реализация новых `*Runner` и базовых Docker-образов.
- Расширение плагиата: AST-сравнение, winnowing/н-граммы, локально-чувствительные хэши.

---